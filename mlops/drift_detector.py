import pandas as pd
import boto3
from io import StringIO
from sklearn.metrics import mean_absolute_error
import argparse
import os
from datetime import datetime, timedelta
import logging
import json
import sys

# Cáº¥u hÃ¬nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger()

def get_csv_from_s3(s3_client, bucket, key):
    """Äá»c file CSV tá»« S3, tráº£ vá» DataFrame rá»—ng náº¿u lá»—i"""
    try:
        obj = s3_client.get_object(Bucket=bucket, Key=key)
        return pd.read_csv(StringIO(obj['Body'].read().decode('utf-8')))
    except Exception as e:
        logger.warning(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y hoáº·c lá»—i Ä‘á»c file {key}: {e}")
        return pd.DataFrame()

def align_dataframe_by_time(df, value_col, time_col='timestamp'):
    """
    Chuáº©n hÃ³a DataFrame vá» index 5 phÃºt (00:00-23:55).
    """
    # 1. Táº¡o index 24 giá» chuáº©n (288 Ä‘iá»ƒm)
    full_time_index = pd.date_range("00:00", "23:55", freq="5T").time
    
    if df.empty:
        return pd.Series(index=full_time_index, dtype=float)
        
    # Äáº£m báº£o cá»™t thá»i gian tá»“n táº¡i vÃ  convert sang datetime
    if time_col in df.columns:
        # LÆ°u Ã½: File CSV hÃ ng ngÃ y cá»§a báº¡n lÆ°u dáº¡ng DD/MM/YYYY nÃªn cáº§n dayfirst=True
        df[time_col] = pd.to_datetime(df[time_col], dayfirst=True, errors='coerce')
        df = df.dropna(subset=[time_col])
    else:
        logging.warning(f"KhÃ´ng tÃ¬m tháº¥y cá»™t thá»i gian '{time_col}' trong dá»¯ liá»‡u.")
        return pd.Series(index=full_time_index, dtype=float)
    
    # 2. Äáº·t cá»™t thá»i gian lÃ m index 
    df = df.set_index(time_col)
    
    # 3. Resample vá» 5 phÃºt
    try:
        # Náº¿u trÃ¹ng index, láº¥y trung bÃ¬nh
        profile_resampled = df[value_col].resample('5T').mean()
    except TypeError:
        df[value_col] = pd.to_numeric(df[value_col], errors='coerce')
        profile_resampled = df[value_col].resample('5T').mean()
    
    # 4. Ná»™i suy (Interpolate) Ä‘á»ƒ láº¥p lá»— há»•ng
    profile_interpolated = profile_resampled.interpolate(method='time')
    
    # 5. NhÃ³m theo giá» trong ngÃ y (Ä‘á»ƒ chuáº©n hÃ³a vá» 1 ngÃ y duy nháº¥t)
    profile_grouped = profile_interpolated.groupby(profile_interpolated.index.time).mean()
    
    # 6. CÄƒn chá»‰nh theo index chuáº©n (00:00 -> 23:55)
    profile_aligned = profile_grouped.reindex(full_time_index)
    
    # 7. Láº¥p Ä‘áº§y lá»— há»•ng (FFill/BFill)
    profile_final = profile_aligned.ffill().bfill() 
    
    return profile_final

def check_drift(args):
    s3 = boto3.client('s3')
    
    # Logic: Check 7 ngÃ y gáº§n nháº¥t tÃ­nh tá»« hÃ´m nay
    today = datetime.now().date()
    
    drift_days_count = 0
    drift_threshold = args.mae_threshold
    limit_days = 3 # NgÆ°á»¡ng: Náº¿u >= 3 ngÃ y lá»—i thÃ¬ bÃ¡o Drift
    
    report_details = {}

    print(f"--- Báº®T Äáº¦U CHECK DRIFT (Window 7 ngÃ y) ---")
    print(f"NgÆ°á»¡ng MAE cho phÃ©p: {drift_threshold}")
    
    # Duyá»‡t qua 7 ngÃ y trÆ°á»›c Ä‘Ã³
    for i in range(1, 8): 
        target_date = today - timedelta(days=i)
        date_str = target_date.strftime('%Y-%m-%d')
        
        # ÄÆ°á»ng dáº«n file
        act_key = f"{args.actual_prefix}{date_str}.csv"
        pred_key = f"{args.prediction_prefix}{date_str}.csv"
        
        # Táº£i dá»¯ liá»‡u
        df_act = get_csv_from_s3(s3, args.bucket, act_key)
        df_pred = get_csv_from_s3(s3, args.bucket, pred_key)
        
        status = "MISSING_DATA"
        mae = None

        if not df_act.empty and not df_pred.empty:
            try:
                # --- ALIGN DATA (QUAN TRá»ŒNG) ---
                # 1. Actuals: CÄƒn chá»‰nh theo cá»™t 'timestamp'
                series_act = align_dataframe_by_time(
                    df_act, 
                    value_col='car_count', 
                    time_col='timestamp'
                )
                
                # 2. Predictions: CÄƒn chá»‰nh theo cá»™t 'prediction_for'
                series_pred = align_dataframe_by_time(
                    df_pred, 
                    value_col='prediction', 
                    time_col='prediction_for'
                )
                
                # 3. TÃ­nh MAE báº±ng Sklearn
                # fillna(0) Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng lá»—i náº¿u interpolate tháº¥t báº¡i (dÃ¹ hiáº¿m)
                y_true = series_act.fillna(0).values
                y_pred = series_pred.fillna(0).values
                
                mae = mean_absolute_error(y_true, y_pred)
                
                if mae > drift_threshold:
                    drift_days_count += 1
                    status = "DRIFT"
                else:
                    status = "OK"
                    
            except Exception as e:
                logger.error(f"Lá»—i tÃ­nh toÃ¡n ngÃ y {date_str}: {e}")
                status = "ERROR"
        
        report_details[date_str] = {"mae": round(mae, 2) if mae is not None else None, "status": status}
        print(f"ğŸ“… {date_str}: {status} (MAE={mae})")

    # --- Káº¾T LUáº¬N ---
    is_drift_detected = drift_days_count >= limit_days
    
    print(f"--- Káº¾T QUáº¢: {drift_days_count}/7 ngÃ y bá»‹ Drift (NgÆ°á»¡ng kÃ­ch hoáº¡t: {limit_days}) ---")
    print(f"--- QUYáº¾T Äá»ŠNH: {'ğŸ”´ RETRAIN' if is_drift_detected else 'ğŸŸ¢ NO RETRAIN'} ---")

    # Xuáº¥t file káº¿t quáº£ JSON
    result = {
        "drift_detected": is_drift_detected,
        "drift_count": drift_days_count,
        "details": report_details,
        "check_timestamp": datetime.now().isoformat()
    }
    
    os.makedirs(args.output_path, exist_ok=True)
    output_file_path = os.path.join(args.output_path, 'drift_check_result.json')
    
    with open(output_file_path, 'w') as f:
        json.dump(result, f, indent=4)
    
    print(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {output_file_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    parser.add_argument('--bucket', type=str, required=True)
    parser.add_argument('--mae-threshold', type=float, default=15.0)
    parser.add_argument('--actual-prefix', type=str, default="daily_actuals/")
    parser.add_argument('--prediction-prefix', type=str, default="daily_predictions/")
    parser.add_argument('--output-path', type=str, default="/opt/ml/processing/output")
    
    args = parser.parse_args()
    check_drift(args)