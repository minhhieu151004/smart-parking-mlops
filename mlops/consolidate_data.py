import argparse
import os
import pandas as pd
import glob
import logging

# Cáº¥u hÃ¬nh Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # Tham sá»‘ output quan trá»ng Ä‘á»ƒ gá»­i sang bÆ°á»›c Train
    parser.add_argument("--output-drift-data", type=str, default="/opt/ml/processing/drift_data")
    
    # CÃ¡c tham sá»‘ khÃ¡c 
    parser.add_argument("--baseline-data-uri", type=str, default="") 
    parser.add_argument("--data-bucket", type=str, default="")
    parser.add_argument("--actual-prefix", type=str, default="") 
    parser.add_argument("--output-path", type=str, default="/opt/ml/processing/output")
    
    args = parser.parse_args()

    logging.info("--- Báº®T Äáº¦U: TRÃCH XUáº¤T Dá»® LIá»†U DRIFT (FINE-TUNING) ---")
    
    # 1. ÄÆ°á»ng dáº«n Input (NÆ¡i SageMaker mount thÆ° má»¥c daily_actuals)
    input_daily_dir = "/opt/ml/processing/input_daily"
    
    # 2. TÃ¬m file CSV má»›i nháº¥t (theo tÃªn file YYYY-MM-DD.csv lÃ  sort Ä‘Æ°á»£c)
    csv_files = glob.glob(os.path.join(input_daily_dir, "*.csv"))
    
    if not csv_files:
        logging.error(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u nÃ o trong {input_daily_dir}")
        # Táº¡o file rá»—ng Ä‘á»ƒ Pipeline khÃ´ng bá»‹ crash, nhÆ°ng logic sau sáº½ dá»«ng
        df_drift = pd.DataFrame(columns=['timestamp', 'car_count'])
    else:
        # Sáº¯p xáº¿p Ä‘á»ƒ láº¥y file má»›i nháº¥t (ngÃ y hÃ´m qua/hÃ´m nay)
        latest_file = sorted(csv_files)[-1]
        logging.info(f"ğŸ“… PhÃ¡t hiá»‡n file dá»¯ liá»‡u má»›i nháº¥t: {os.path.basename(latest_file)}")
        
        # 3. Äá»c dá»¯ liá»‡u
        df_drift = pd.read_csv(latest_file)
        
        # Xá»­ lÃ½ format timestamp náº¿u cáº§n (Ä‘á»ƒ khá»›p vá»›i train_pipeline)
        if 'timestamp' in df_drift.columns:
            df_drift['timestamp'] = pd.to_datetime(df_drift['timestamp']).dt.strftime('%d/%m/%Y %H:%M:%S')

        logging.info(f"âœ… ÄÃ£ load {len(df_drift)} dÃ²ng dá»¯ liá»‡u Ä‘á»ƒ Fine-tune.")

    # 4. LÆ°u file output (train.csv)
    os.makedirs(args.output_drift_data, exist_ok=True)
    drift_output_file = os.path.join(args.output_drift_data, "train.csv")
    
    df_drift.to_csv(drift_output_file, index=False)
    logging.info(f"ğŸ’¾ ÄÃ£ lÆ°u file training vÃ o: {drift_output_file}")

    logging.info("--- HOÃ€N Táº¤T ---")