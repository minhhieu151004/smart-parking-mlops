import boto3
import pandas as pd
import os
import io
from datetime import datetime, timedelta
from boto3.dynamodb.conditions import Key
from io import StringIO

# --- C·∫§U H√åNH ---
BUCKET_NAME = os.environ.get('S3_BUCKET', 'kltn-smart-parking-data')
SENSOR_ID = 'camera-01'
TABLE_RAW = 'SmartParkingRawData'
TABLE_PRED = 'SmartParkingPredictions'
PREDICTION_WINDOW_MINUTES = 60  # M√¥ h√¨nh d·ª± ƒëo√°n tr∆∞·ªõc 60'

s3 = boto3.client('s3')
dynamodb = boto3.resource('dynamodb')

def query_items_by_range(table_name, start_time_str, end_time_str):
    """Query DynamoDB theo kho·∫£ng th·ªùi gian t√πy ch·ªânh."""
    table = dynamodb.Table(table_name)
    items = []
    try:
        print(f"   Querying {table_name}: {start_time_str} -> {end_time_str}")
        response = table.query(
            KeyConditionExpression=Key('sensor_id').eq(SENSOR_ID) & Key('timestamp').between(start_time_str, end_time_str)
        )
        items.extend(response['Items'])
        
        while 'LastEvaluatedKey' in response:
            response = table.query(
                KeyConditionExpression=Key('sensor_id').eq(SENSOR_ID) & Key('timestamp').between(start_time_str, end_time_str),
                ExclusiveStartKey=response['LastEvaluatedKey']
            )
            items.extend(response['Items'])
        return items
    except Exception as e:
        print(f"Error querying {table_name}: {e}")
        return []

def export_archive_to_s3(df, s3_folder, target_date_str):
    if df.empty:
        return

    # S·∫Øp x·∫øp l·∫°i cho chu·∫©n
    if 'timestamp' in df.columns:
        df = df.sort_values('timestamp')
        # Format l·∫°i timestamp
        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%d/%m/%Y %H:%M:%S')
        
        # N·∫øu l√† file prediction, format lu√¥n c·ªôt prediction_for
        if 'prediction_for' in df.columns:
             df['prediction_for'] = pd.to_datetime(df['prediction_for']).dt.strftime('%d/%m/%Y %H:%M:%S')

    if 'sensor_id' in df.columns:
         df = df.drop(columns=['sensor_id'], errors='ignore')

    # L∆∞u l√™n S3
    csv_buffer = StringIO()
    df.to_csv(csv_buffer, index=False)
    
    s3_key = f"{s3_folder}/{target_date_str}.csv"
    s3.put_object(Bucket=BUCKET_NAME, Key=s3_key, Body=csv_buffer.getvalue())
    print(f"‚úÖ ƒê√£ l∆∞u file {s3_key} ({len(df)} d√≤ng)")

# --- H√ÄM HANDLER ---
def lambda_handler(event, context):
    now = datetime.now()
    
    # 1. X√°c ƒë·ªãnh ng√†y m·ª•c ti√™u (H√¥m qua)
    target_date = (now - timedelta(days=1)).date()
    target_date_str = target_date.strftime('%Y-%m-%d')
    
    print(f"--- B·∫ÆT ƒê·∫¶U T·ªîNG H·ª¢P D·ªÆ LI·ªÜU CHO NG√ÄY: {target_date_str} ---")

    # ==============================================================================
    # X·ª¨ L√ù 1: RAW DATA (D·ªØ li·ªáu th·ª±c t·∫ø) - Logic: D·ª±a v√†o timestamp (l√∫c g·ª≠i)
    # ==============================================================================
    # Raw data th√¨ timestamp ch√≠nh l√† th·ªùi ƒëi·ªÉm th·ª±c t·∫ø, n√™n query ƒë√∫ng ng√†y l√† ƒë∆∞·ª£c
    raw_start = f"{target_date_str}T00:00:00"
    raw_end = f"{target_date_str}T23:59:59"
    
    raw_items = query_items_by_range(TABLE_RAW, raw_start, raw_end)
    if raw_items:
        df_raw = pd.DataFrame(raw_items)
        # L∆∞u Actuals
        export_archive_to_s3(df_raw, "daily_actuals", target_date_str)
        # G·ªôp Master (Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ h√†m consolidate_master_file ·ªü tr√™n)
        # consolidate_master_file(s3, df_raw) 
    else:
        print(f"‚ö†Ô∏è Kh√¥ng c√≥ Raw Data cho ng√†y {target_date_str}")

    # ==============================================================================
    # X·ª¨ L√ù 2: PREDICTIONS (D·ªØ li·ªáu d·ª± b√°o) - Logic: D·ª±a v√†o prediction_for
    # ==============================================================================
    # ƒê·ªÉ l·∫•y ƒë·ªß d·ª± ƒëo√°n CHO ng√†y 8/12, ta c·∫ßn l·∫•y c√°c d·ª± ƒëo√°n ƒë∆∞·ª£c T·∫†O RA t·ª´:
    # 22:00 ng√†y 7/12 (d·ª± ƒëo√°n cho 23:00 -> 00:00 ng√†y 8/12)
    # ƒë·∫øn 23:00 ng√†y 8/12 (d·ª± ƒëo√°n cho 00:00 ng√†y 9/12 - c√°i n√†y s·∫Ω b·ªã l·ªçc b·ªè sau)
    
    # M·ªü r·ªông c·ª≠a s·ªï query l√πi v·ªÅ qu√° kh·ª© (Buffer th√™m 2 ti·∫øng cho ch·∫Øc)
    buffer_hours = 2 
    query_start_dt = datetime.combine(target_date, datetime.min.time()) - timedelta(hours=buffer_hours)
    query_end_dt = datetime.combine(target_date, datetime.max.time())
    
    pred_query_start = query_start_dt.isoformat()
    pred_query_end = query_end_dt.isoformat()
    
    print(f"üîç Qu√©t b·∫£ng Prediction r·ªông h∆°n: t·ª´ {pred_query_start} ƒë·∫øn {pred_query_end}")
    pred_items = query_items_by_range(TABLE_PRED, pred_query_start, pred_query_end)

    if pred_items:
        df_pred = pd.DataFrame(pred_items)
        
        # --- LOGIC L·ªåC QUAN TR·ªåNG ---
        # Chuy·ªÉn ƒë·ªïi prediction_for sang datetime ƒë·ªÉ so s√°nh
        df_pred['prediction_for_dt'] = pd.to_datetime(df_pred['prediction_for'])
        
        # Ch·ªâ gi·ªØ l·∫°i nh·ªØng d√≤ng m√† prediction_for thu·ªôc ƒë√∫ng ng√†y m·ª•c ti√™u
        df_pred_filtered = df_pred[df_pred['prediction_for_dt'].dt.date == target_date].copy()
        
        print(f"   -> T√¨m th·∫•y {len(df_pred)} d·ª± ƒëo√°n trong kho·∫£ng query.")
        print(f"   -> Sau khi l·ªçc theo 'prediction_for' == {target_date_str}: C√≤n {len(df_pred_filtered)} d√≤ng.")
        
        # X√≥a c·ªôt t·∫°m
        df_pred_filtered = df_pred_filtered.drop(columns=['prediction_for_dt'])
        
        # L∆∞u file Archive
        export_archive_to_s3(df_pred_filtered, "daily_predictions", target_date_str)
    else:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Prediction n√†o.")

    return {"statusCode": 200, "body": "Success"}